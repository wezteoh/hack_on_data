{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook contains a `Python 2` / `PySpark` script to find the top $N$ words for the positive and negative reviews in a given cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import gzip # To parse gzip file\n",
    "import re # Regex for text processing\n",
    "import os # For setting up Mongo-Spark connector\n",
    "import csv # To read/write CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise PySpark session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `MongoDB-Spark` connector when starting up `PySpark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "packages = 'org.mongodb.spark:mongo-spark-connector_2.11:2.2.0'\n",
    "dedicated_memory = '4g'\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages {} --driver-memory {} pyspark-shell' \\\n",
    "    .format(packages, dedicated_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find SPARK_HOME\n",
    "findspark.init()\n",
    "\n",
    "# Create SparkSession\n",
    "spark = (pyspark.sql.SparkSession\n",
    "         .builder.appName('WordProcessing')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Pandas HTML display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     8,
     38,
     51
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    '''\n",
    "    Unzip a json.gz at `path` and returns a generator.\n",
    "    '''\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for line in g:\n",
    "        yield eval(line)\n",
    "\n",
    "def import_to_mongo(path, coll, db='hackon', create_index=True):\n",
    "    '''\n",
    "    Unzip and import json.gz file from `path` and loads it into mongo server.\n",
    "    Create database index if `create_index` is True. \n",
    "    '''\n",
    "    # Obtain handle to Mongo database and collection\n",
    "    client = pymongo.MongoClient()\n",
    "    collection = client[db][coll]\n",
    "    \n",
    "    # Return prematurely if database.collection already exists\n",
    "    if (collection.count() != 0):\n",
    "        print '{}.{} already exists on MongoDisk server. Exiting without loading JSON data.'.format(db, coll)\n",
    "        return\n",
    "    \n",
    "    # Insert datapoints into Mongo database\n",
    "    try:\n",
    "        collection.insert_many((datapoint for datapoint in parse(path)))\n",
    "        print 'JSON data successfully imported to Mongo at \\'{}.{}.\\''.format(db, coll)\n",
    "    except Exception as e:\n",
    "        print 'Error loading data.\\n{}'.format(e)\n",
    "        client.close()\n",
    "        return\n",
    "    \n",
    "    if not create_index:\n",
    "        client.close()\n",
    "        return\n",
    "    \n",
    "    # Create database index for improved searching\n",
    "    # collection.create_index([('asin', pymongo.ASCENDING), ('reviewerID', pymongo.DESCENDING)])\n",
    "\n",
    "def load_mongo_to_spark(coll, db='hackon'):\n",
    "    '''\n",
    "    Load the Mongo database to a Spark Session and returns the Spark DataFrame\n",
    "    '''\n",
    "    try:\n",
    "        return (spark\n",
    "                .read\n",
    "                .format('com.mongodb.spark.sql.DefaultSource')\n",
    "                .option('uri', 'mongodb://127.0.0.1/{}.{}'.format(db, coll))\n",
    "                .load())\n",
    "    except Exception as e:\n",
    "        print 'Failed to create Spark dataframe.\\n{}'.format(e)\n",
    "\n",
    "def displayDF(sparkDF, n=10):\n",
    "    '''\n",
    "    Interactively displays the first n rows of a sparkDF as a pandas dataframe\n",
    "    '''\n",
    "    return (sparkDF\n",
    "            .limit(n)\n",
    "            .drop('_id', 'unixReviewTime')\n",
    "            .toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hackon.baby already exists on MongoDisk server. Exiting without loading JSON data.\n"
     ]
    }
   ],
   "source": [
    "import_to_mongo('../../Datasets/reviews_Baby.json.gz', coll='baby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Processing Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function belowÂ takes in a Spark DataFrame containing reviews of a particular cluster. It returns a new DataFrame with two appended columns listing the top $N$ words based on *tf-idf* scores for good and bad reviews. \n",
    "\n",
    "> By default, *good reviews* are defined as reviews with **4-star** ratings and above, with the rest defined as *bad reviews*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mongo toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def append_toy_clusterID(DF):\n",
    "#     '''\n",
    "#     Append a toy 'clusterID' column to `DF` by assigning each row the clusterID corresponding to its '_id' field's last digit.\n",
    "#     '''\n",
    "#     def _create_toy_clusterID(_id):\n",
    "#         return int(int(_id, 16) % 10)\n",
    "    \n",
    "#     udf = F.udf(lambda _id: _create_toy_clusterID(_id[0]), T.IntegerType())\n",
    "    \n",
    "#     return DF.withColumn('clusterID', udf(F.col('_id')))\n",
    "\n",
    "# rawDF = append_toy_clusterID(load_mongo_to_spark('video_games'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>clusterId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188399313</td>\n",
       "      <td>Lifefactory 4oz BPA Free Glass Baby Bottles - 4-pack-raspberry and Lilac</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188399518</td>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188399399</td>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316967297</td>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>615447279</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>670062049</td>\n",
       "      <td>5 Pink Gumdrops + One Pacifier Clip</td>\n",
       "      <td>2372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>705391752</td>\n",
       "      <td>A Tale of Baby's Days with Peter Rabbit</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>097293751X</td>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, Schedule Log</td>\n",
       "      <td>3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>974671517</td>\n",
       "      <td>Wee Gallery Twins Board Book</td>\n",
       "      <td>2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>980027519</td>\n",
       "      <td>Nature's Lullabies First and Second Year Calendars</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  188399313    \n",
       "1  188399518    \n",
       "2  188399399    \n",
       "3  316967297    \n",
       "4  615447279    \n",
       "5  670062049    \n",
       "6  705391752    \n",
       "7  097293751X   \n",
       "8  974671517    \n",
       "9  980027519    \n",
       "\n",
       "                                                                                               title  \\\n",
       "0  Lifefactory 4oz BPA Free Glass Baby Bottles - 4-pack-raspberry and Lilac                            \n",
       "1  Planetwise Flannel Wipes                                                                            \n",
       "2  Planetwise Wipe Pouch                                                                               \n",
       "3  Annas Dream Full Quilt with 2 Shams                                                                 \n",
       "4  Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book   \n",
       "5  5 Pink Gumdrops + One Pacifier Clip                                                                 \n",
       "6  A Tale of Baby's Days with Peter Rabbit                                                             \n",
       "7  Baby Tracker&reg; - Daily Childcare Journal, Schedule Log                                           \n",
       "8  Wee Gallery Twins Board Book                                                                        \n",
       "9  Nature's Lullabies First and Second Year Calendars                                                  \n",
       "\n",
       "   clusterId  \n",
       "0  523        \n",
       "1  975        \n",
       "2  802        \n",
       "3  281        \n",
       "4  1130       \n",
       "5  2372       \n",
       "6  1014       \n",
       "7  3044       \n",
       "8  2231       \n",
       "9  11         "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw1DF = (spark\n",
    "         .read\n",
    "         .format('com.databricks.spark.csv')\n",
    "         .options(header='true', inferschema='true')\n",
    "         .load('../../Datasets/baby_product_summary.csv')\n",
    "         .dropna()\n",
    "         )\n",
    "#          .withColumn('int', check_for_int('clusterID'))\n",
    "#          .filter(F.col('int') == True)\n",
    "#          .select('asin', 'clusterID'))\n",
    "displayDF(raw1DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0188399313</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>They work very well. Easy to clean, we wash them in the dishwasher every day. Our LO loves to hold on to the bottle and the plastic covering makes it easy for her to hold on to.</td>\n",
       "      <td>05 27, 2013</td>\n",
       "      <td>A28O3NP6WR5517</td>\n",
       "      <td>Jennifer gymer</td>\n",
       "      <td>These bottles are great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0188399399</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>it came early and was not disappointed. i love planet wise bags and now my wipe holder. it keps my osocozy wipes moist and does not leak. highly recommend it.</td>\n",
       "      <td>04 9, 2013</td>\n",
       "      <td>AX0M1Z6ZWO52J</td>\n",
       "      <td>Ash M.</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  0188399313  [0, 0]  5.0       \n",
       "1  0188399399  [1, 1]  5.0       \n",
       "\n",
       "                                                                                                                                                                          reviewText  \\\n",
       "0  They work very well. Easy to clean, we wash them in the dishwasher every day. Our LO loves to hold on to the bottle and the plastic covering makes it easy for her to hold on to.   \n",
       "1  it came early and was not disappointed. i love planet wise bags and now my wipe holder. it keps my osocozy wipes moist and does not leak. highly recommend it.                      \n",
       "\n",
       "    reviewTime      reviewerID    reviewerName                   summary  \n",
       "0  05 27, 2013  A28O3NP6WR5517  Jennifer gymer  These bottles are great!  \n",
       "1  04 9, 2013   AX0M1Z6ZWO52J   Ash M.          perfect                   "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw2DF = load_mongo_to_spark('baby')\n",
    "displayDF(raw2DF, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>clusterID</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000JJY13Y</td>\n",
       "      <td>3210</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A very well-made toy. Mine had been in the store for months but was still in good shape. I'm sure he'll stand up to much good-natured rough-housing. They've even made a few adjustments to make him more cuddly -- the real Grover on TV has plastic eyes, whereas this Grover's eyes are made of cloth. Good thinking -- I'm sure this Grover will be accompanying lots of kids to Dreamland.</td>\n",
       "      <td>12 23, 2008</td>\n",
       "      <td>A1BSO69KR49GKF</td>\n",
       "      <td>Bradley D. Hall</td>\n",
       "      <td>Top-notch!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000JJY13Y</td>\n",
       "      <td>3210</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This was a great gift for my 5-year old grandson. He likes Grover and the puppet is almost as big as he is. Very cute and still cuddly even at 36 inches. Also came very quickly after ordering--very satisfied.</td>\n",
       "      <td>01 15, 2007</td>\n",
       "      <td>A2PMST8J2GYPPH</td>\n",
       "      <td>J. Barclay</td>\n",
       "      <td>Grover puppet SO cute!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000JJY13Y</td>\n",
       "      <td>3210</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We love our Grover, with this muppet it is easy to feel like Grover yourself as you move his mouth and arms while doing his voice. The hand hole for the mouth is plenty big enough for an adult but also allows operation by small hands as well. The hands have holes for all of his fingers and are a little tight for my hands (as a 34 yo male) but they still work ok.Grover seems to be well stitched and durable, though he is certainly not machine washable because of his inner puppet parts. Maybe the best part is that at with Grover's height, he is right at or close to eye level with your 4-6 yo child, which makes him seem more real.</td>\n",
       "      <td>12 30, 2008</td>\n",
       "      <td>A3FAE1PANJQ4RR</td>\n",
       "      <td>Muppet Man</td>\n",
       "      <td>This Grover is awesome and fun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  clusterID helpful  overall  \\\n",
       "0  B000JJY13Y  3210       [0, 0]  5.0       \n",
       "1  B000JJY13Y  3210       [0, 0]  5.0       \n",
       "2  B000JJY13Y  3210       [0, 0]  5.0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   reviewText  \\\n",
       "0  A very well-made toy. Mine had been in the store for months but was still in good shape. I'm sure he'll stand up to much good-natured rough-housing. They've even made a few adjustments to make him more cuddly -- the real Grover on TV has plastic eyes, whereas this Grover's eyes are made of cloth. Good thinking -- I'm sure this Grover will be accompanying lots of kids to Dreamland.                                                                                                                                                                                                                                                              \n",
       "1  This was a great gift for my 5-year old grandson. He likes Grover and the puppet is almost as big as he is. Very cute and still cuddly even at 36 inches. Also came very quickly after ordering--very satisfied.                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "2  We love our Grover, with this muppet it is easy to feel like Grover yourself as you move his mouth and arms while doing his voice. The hand hole for the mouth is plenty big enough for an adult but also allows operation by small hands as well. The hands have holes for all of his fingers and are a little tight for my hands (as a 34 yo male) but they still work ok.Grover seems to be well stitched and durable, though he is certainly not machine washable because of his inner puppet parts. Maybe the best part is that at with Grover's height, he is right at or close to eye level with your 4-6 yo child, which makes him seem more real.   \n",
       "\n",
       "    reviewTime      reviewerID     reviewerName  \\\n",
       "0  12 23, 2008  A1BSO69KR49GKF  Bradley D. Hall   \n",
       "1  01 15, 2007  A2PMST8J2GYPPH  J. Barclay        \n",
       "2  12 30, 2008  A3FAE1PANJQ4RR  Muppet Man        \n",
       "\n",
       "                          summary  \n",
       "0  Top-notch!                      \n",
       "1  Grover puppet SO cute!          \n",
       "2  This Grover is awesome and fun  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF = raw1DF.join(raw2DF, on='asin')\n",
    "displayDF(rawDF, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stopwords\n",
    "A list of stopwords is loaded as a Python list and broadcasted in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of stopwords:\n",
      "\n",
      "['all', 'just', 'being', 'over', 'both', 'through', 'yourselves', 'its', 'before', 'with', 'had', 'should', 'to', 'only', 'under', 'ours', 'has', 'do', 'them', 'his', 'very', 'they', 'not', 'during', 'now', 'him', 'nor', 'did', 'these', 't', 'each', 'where', 'because', 'doing', 'theirs', 'some', 'are', 'our', 'ourselves', 'out', 'what', 'for', 'below', 'does', 'above', 'between', 'she', 'be', 'we', 'after', 'here', 'hers', 'by', 'on', 'about', 'of', 'against', 's', 'or', 'own', 'into', 'yourself', 'down', 'your', 'from', 'her', 'whom', 'there', 'been', 'few', 'too', 'themselves', 'was', 'until', 'more', 'himself', 'that', 'but', 'off', 'herself', 'than', 'those', 'he', 'me', 'myself', 'this', 'up', 'will', 'while', 'can', 'were', 'my', 'and', 'then', 'is', 'in', 'am', 'it', 'an', 'as', 'itself', 'at', 'have', 'further', 'their', 'if', 'again', 'no', 'when', 'same', 'any', 'how', 'other', 'which', 'you', 'who', 'most', 'such', 'why', 'a', 'don', 'i', 'having', 'so', 'the', 'yours', 'once', '']\n"
     ]
    }
   ],
   "source": [
    "# Load stopwords into list\n",
    "with open('stopwords.csv', 'r') as csvFile:\n",
    "    fileReader = csv.reader(csvFile)\n",
    "    stopwords = []\n",
    "    for word in fileReader:\n",
    "        stopwords.extend(word)\n",
    "        \n",
    "# Add '' to stopwords\n",
    "stopwords.append('')\n",
    "\n",
    "# Broadcast stopwords\n",
    "stopwords_broadcast = spark.sparkContext.broadcast(stopwords)\n",
    "        \n",
    "print 'List of stopwords:\\n\\n{}'.format(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess `rawDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0,
     20
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_helpful_reviews(sparkDF, pct_helpful, min_votes):\n",
    "    '''\n",
    "    Return a dataframe filtered by comments that are at least `pct_helpful`% helpful \n",
    "    and contain a minimum number of votes.\n",
    "    '''\n",
    "    def _filter_helpful_reviews(votes, pct_helpful, min_votes):\n",
    "        '''\n",
    "        Return bool if comment are at least `pct_helpful`% helpful and have at least `min_votes` vote.\n",
    "        \n",
    "        Inputs:\n",
    "            votes: A list of votes by [helpful, total_votes]\n",
    "            pct_helpful: A float\n",
    "            min_votes: A float\n",
    "        '''\n",
    "        return (votes[1] >= min_votes and (float(votes[0]) / votes[1] >= pct_helpful))\n",
    "    \n",
    "    udf = F.udf(lambda votes: _filter_helpful_reviews(votes, pct_helpful, min_votes), T.BooleanType())\n",
    "    \n",
    "    return sparkDF.filter(udf(F.col('helpful')))\n",
    "\n",
    "def preprocess_DF(rawDF):\n",
    "    '''\n",
    "    Preprocess text of dataframe by:\n",
    "        - selecting relevant columns ('clusterID', 'overall', 'review')\n",
    "        - concatenating 'summary' and 'reviewText' columns\n",
    "        - removing punctuations\n",
    "        - filtering out stopwords\n",
    "    '''\n",
    "    \n",
    "    def _filter_stopwords(text):\n",
    "        '''\n",
    "        Input:\n",
    "            text: A string concatenation of the columns 'summary' and 'reviewText'.\n",
    "        Returns:\n",
    "            A list of strings with stopwords filtered out.\n",
    "        '''\n",
    "        string_list = re.split(r'\\W+', text.lower())\n",
    "        \n",
    "        return [word for word in string_list if word not in stopwords_broadcast.value]\n",
    "    \n",
    "    udf = F.udf(lambda text: _filter_stopwords(text), T.ArrayType(T.StringType()))\n",
    "    \n",
    "    return (rawDF\n",
    "            .select(F.concat_ws('-', \n",
    "                                F.col('asin'), \n",
    "                                F.col('reviewerID')).alias('reviewID'),\n",
    "                    F.col('clusterID'),\n",
    "                    F.col('overall'), \n",
    "                    udf(F.concat_ws(' ', \n",
    "                                    F.col('summary'), \n",
    "                                    F.col('reviewText'))).alias('reviews')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewID</th>\n",
       "      <th>clusterID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000JK2LB2-A3PPEED8SHD8R7</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[perfect, travelling, toddler, live, africa, travel, us, africa, regularly, bought, last, journey, love, takes, little, room, much, easier, using, stroller, folds, nicely, fit, overhead, son, loved, riding, thought, little, tray, great, gate, one, pilots, stopped, take, picture, could, get, one, child, use, also, came, handy, crowded, gate, weren, many, seats, baggage, claim, travel, toddler, know, someone, buy, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000JK2LB2-A3AC5BCN2AA2CZ</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[best, money, ever, spent, ride, carry, saved, sanity, making, cross, country, trip, two, layovers, three, children, age, five, attached, one, two, carry, ons, wore, newborn, sling, sailed, experience, everywhere, went, travelers, complimented, asked, bought, re, versatile, tray, head, rest, making, airport, snacking, easy, sturdy, sleek, cute, easy, use, re, planning, trip, promise, won, sorry, bought]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000JK2LB2-A15J3MCQ5GV6AJ</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[awesome, daughter, hyper, hard, keep, running, place, traveling, bit, hassle, got, awesome, ride, carry, saved, seats, enjoying, ride, watching, everything, painting, playing, eating, moving, really, awesome, product, thank, think, twice, getting, make, traveling, toddlers, pleasurable, experience]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000JK2LB2-A2PSQ6VL6NXENW</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[travel, without, one, 2, years, first, thing, pack, happier, travellers, since, got, one, easy, airports, days, extra, hand, free, sturdy, stays, clean, mine, hardly, looks, used, son, enjoyed, daughter, says, chair, sees, pull, seat, sit, great, know, child, safely, strapped, behind, checking, desk, looking, boarding, pass, show, yet, another, person, getting, dressed, security, otherwise, distracted, run, make, flight, connection, kids, think, great, fun, strap, around, middle, carry, bag, around, handle, times, fast, headrest, used, traytable, useful, gate, snacks, activities, even, bring, kids, airplane, aisle, fold, seat, store, onboard, quite, flat, folded, love, couldn, without]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000JK2LB2-A1V14KOGUJAC5T</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[genius, invented, bought, product, help, move, two, kids, one, stroller, year, half, older, three, half, happy, sit, watch, people, around, able, move, fast, maneuver, even, stroller, hand, good, quality, folds, easy, fits, easily, board, hand, bag, give, five, stars, could, buy, hesitate, worths, every, penny]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    reviewID  clusterID  overall  \\\n",
       "0  B000JK2LB2-A3PPEED8SHD8R7  291        5.0       \n",
       "1  B000JK2LB2-A3AC5BCN2AA2CZ  291        5.0       \n",
       "2  B000JK2LB2-A15J3MCQ5GV6AJ  291        5.0       \n",
       "3  B000JK2LB2-A2PSQ6VL6NXENW  291        5.0       \n",
       "4  B000JK2LB2-A1V14KOGUJAC5T  291        5.0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   reviews  \n",
       "0  [perfect, travelling, toddler, live, africa, travel, us, africa, regularly, bought, last, journey, love, takes, little, room, much, easier, using, stroller, folds, nicely, fit, overhead, son, loved, riding, thought, little, tray, great, gate, one, pilots, stopped, take, picture, could, get, one, child, use, also, came, handy, crowded, gate, weren, many, seats, baggage, claim, travel, toddler, know, someone, buy, product]                                                                                                                                                                                                                                                                                 \n",
       "1  [best, money, ever, spent, ride, carry, saved, sanity, making, cross, country, trip, two, layovers, three, children, age, five, attached, one, two, carry, ons, wore, newborn, sling, sailed, experience, everywhere, went, travelers, complimented, asked, bought, re, versatile, tray, head, rest, making, airport, snacking, easy, sturdy, sleek, cute, easy, use, re, planning, trip, promise, won, sorry, bought]                                                                                                                                                                                                                                                                                                   \n",
       "2  [awesome, daughter, hyper, hard, keep, running, place, traveling, bit, hassle, got, awesome, ride, carry, saved, seats, enjoying, ride, watching, everything, painting, playing, eating, moving, really, awesome, product, thank, think, twice, getting, make, traveling, toddlers, pleasurable, experience]                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "3  [travel, without, one, 2, years, first, thing, pack, happier, travellers, since, got, one, easy, airports, days, extra, hand, free, sturdy, stays, clean, mine, hardly, looks, used, son, enjoyed, daughter, says, chair, sees, pull, seat, sit, great, know, child, safely, strapped, behind, checking, desk, looking, boarding, pass, show, yet, another, person, getting, dressed, security, otherwise, distracted, run, make, flight, connection, kids, think, great, fun, strap, around, middle, carry, bag, around, handle, times, fast, headrest, used, traytable, useful, gate, snacks, activities, even, bring, kids, airplane, aisle, fold, seat, store, onboard, quite, flat, folded, love, couldn, without]  \n",
       "4  [genius, invented, bought, product, help, move, two, kids, one, stroller, year, half, older, three, half, happy, sit, watch, people, around, able, move, fast, maneuver, even, stroller, hand, good, quality, folds, easy, fits, easily, board, hand, bag, give, five, stars, could, buy, hesitate, worths, every, penny]                                                                                                                                                                                                                                                                                                                                                                                                "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessedDF = preprocess_DF(filter_helpful_reviews(rawDF, pct_helpful=.5, min_votes=3))\n",
    "displayDF(preprocessedDF, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for illegal `clusterID`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewID</th>\n",
       "      <th>clusterID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviewID, clusterID, overall, reviews]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@F.udf(returnType=T.BooleanType())\n",
    "def check_int_instance(clusterID):\n",
    "    return True if isinstance(clusterID, int) else False\n",
    "displayDF(preprocessedDF.filter(check_int_instance(F.col('clusterID')) == False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label ratings for `preprocessedDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     1
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.BooleanType())\n",
    "def label_review_quality(rating, min_good_review_rating=4):\n",
    "    '''\n",
    "    UDF to append a column label of 'isPositiveReview' to the DataFrame.\n",
    "    \n",
    "    Inputs:\n",
    "        rating: Rating from 1.0 to 5.0 (int expressed as float)\n",
    "    Outputs:\n",
    "        True if review has a rating of at least `min_good_review_rating`, otherwise False.\n",
    "    '''\n",
    "    return True if rating >= min_good_review_rating else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewID</th>\n",
       "      <th>clusterID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviews</th>\n",
       "      <th>positiveReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000JK2LB2-A3PPEED8SHD8R7</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[perfect, travelling, toddler, live, africa, travel, us, africa, regularly, bought, last, journey, love, takes, little, room, much, easier, using, stroller, folds, nicely, fit, overhead, son, loved, riding, thought, little, tray, great, gate, one, pilots, stopped, take, picture, could, get, one, child, use, also, came, handy, crowded, gate, weren, many, seats, baggage, claim, travel, toddler, know, someone, buy, product]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000JK2LB2-A3AC5BCN2AA2CZ</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[best, money, ever, spent, ride, carry, saved, sanity, making, cross, country, trip, two, layovers, three, children, age, five, attached, one, two, carry, ons, wore, newborn, sling, sailed, experience, everywhere, went, travelers, complimented, asked, bought, re, versatile, tray, head, rest, making, airport, snacking, easy, sturdy, sleek, cute, easy, use, re, planning, trip, promise, won, sorry, bought]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000JK2LB2-A15J3MCQ5GV6AJ</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[awesome, daughter, hyper, hard, keep, running, place, traveling, bit, hassle, got, awesome, ride, carry, saved, seats, enjoying, ride, watching, everything, painting, playing, eating, moving, really, awesome, product, thank, think, twice, getting, make, traveling, toddlers, pleasurable, experience]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000JK2LB2-A2PSQ6VL6NXENW</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[travel, without, one, 2, years, first, thing, pack, happier, travellers, since, got, one, easy, airports, days, extra, hand, free, sturdy, stays, clean, mine, hardly, looks, used, son, enjoyed, daughter, says, chair, sees, pull, seat, sit, great, know, child, safely, strapped, behind, checking, desk, looking, boarding, pass, show, yet, another, person, getting, dressed, security, otherwise, distracted, run, make, flight, connection, kids, think, great, fun, strap, around, middle, carry, bag, around, handle, times, fast, headrest, used, traytable, useful, gate, snacks, activities, even, bring, kids, airplane, aisle, fold, seat, store, onboard, quite, flat, folded, love, couldn, without]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000JK2LB2-A1V14KOGUJAC5T</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[genius, invented, bought, product, help, move, two, kids, one, stroller, year, half, older, three, half, happy, sit, watch, people, around, able, move, fast, maneuver, even, stroller, hand, good, quality, folds, easy, fits, easily, board, hand, bag, give, five, stars, could, buy, hesitate, worths, every, penny]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    reviewID  clusterID  overall  \\\n",
       "0  B000JK2LB2-A3PPEED8SHD8R7  291        5.0       \n",
       "1  B000JK2LB2-A3AC5BCN2AA2CZ  291        5.0       \n",
       "2  B000JK2LB2-A15J3MCQ5GV6AJ  291        5.0       \n",
       "3  B000JK2LB2-A2PSQ6VL6NXENW  291        5.0       \n",
       "4  B000JK2LB2-A1V14KOGUJAC5T  291        5.0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   reviews  \\\n",
       "0  [perfect, travelling, toddler, live, africa, travel, us, africa, regularly, bought, last, journey, love, takes, little, room, much, easier, using, stroller, folds, nicely, fit, overhead, son, loved, riding, thought, little, tray, great, gate, one, pilots, stopped, take, picture, could, get, one, child, use, also, came, handy, crowded, gate, weren, many, seats, baggage, claim, travel, toddler, know, someone, buy, product]                                                                                                                                                                                                                                                                                  \n",
       "1  [best, money, ever, spent, ride, carry, saved, sanity, making, cross, country, trip, two, layovers, three, children, age, five, attached, one, two, carry, ons, wore, newborn, sling, sailed, experience, everywhere, went, travelers, complimented, asked, bought, re, versatile, tray, head, rest, making, airport, snacking, easy, sturdy, sleek, cute, easy, use, re, planning, trip, promise, won, sorry, bought]                                                                                                                                                                                                                                                                                                    \n",
       "2  [awesome, daughter, hyper, hard, keep, running, place, traveling, bit, hassle, got, awesome, ride, carry, saved, seats, enjoying, ride, watching, everything, painting, playing, eating, moving, really, awesome, product, thank, think, twice, getting, make, traveling, toddlers, pleasurable, experience]                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "3  [travel, without, one, 2, years, first, thing, pack, happier, travellers, since, got, one, easy, airports, days, extra, hand, free, sturdy, stays, clean, mine, hardly, looks, used, son, enjoyed, daughter, says, chair, sees, pull, seat, sit, great, know, child, safely, strapped, behind, checking, desk, looking, boarding, pass, show, yet, another, person, getting, dressed, security, otherwise, distracted, run, make, flight, connection, kids, think, great, fun, strap, around, middle, carry, bag, around, handle, times, fast, headrest, used, traytable, useful, gate, snacks, activities, even, bring, kids, airplane, aisle, fold, seat, store, onboard, quite, flat, folded, love, couldn, without]   \n",
       "4  [genius, invented, bought, product, help, move, two, kids, one, stroller, year, half, older, three, half, happy, sit, watch, people, around, able, move, fast, maneuver, even, stroller, hand, good, quality, folds, easy, fits, easily, board, hand, bag, give, five, stars, could, buy, hesitate, worths, every, penny]                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "\n",
       "   positiveReview  \n",
       "0  True            \n",
       "1  True            \n",
       "2  True            \n",
       "3  True            \n",
       "4  True            "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarizedDF = (preprocessedDF\n",
    "               .withColumn('positiveReview', label_review_quality('overall')))\n",
    "displayDF(polarizedDF, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82591"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarizedDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate ratings by `clusterID` and `positiveReview`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     1,
     12
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.ArrayType(T.StringType()))\n",
    "def flatten(nested_list):\n",
    "    '''\n",
    "    Flatten a list of list to a one dimensional list.\n",
    "    '''\n",
    "    final_list = []\n",
    "    for list_ in nested_list:\n",
    "        final_list.extend(list_)\n",
    "        \n",
    "    return final_list\n",
    "\n",
    "@F.udf(returnType=T.BooleanType())\n",
    "def bool_invert(boolean):\n",
    "    '''\n",
    "    Invert the value of a boolean\n",
    "    '''\n",
    "    return not boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterID</th>\n",
       "      <th>positiveReview</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[great, nightlight, replacement, nightlight, died, 4, 1, 2, years, use, terrific, design, soft, design, ease, use, make, perfect, nightlight, son, 4, 1, 2, loves, sharp, tooth, dinosaur, changing, colors, even, perfected, selecting, color, likes, night, highly, recommend, product, one, child, great, gift, sent, rex, gift, boy, mother, wrote, love, tyrannosaurus, light, anthony, favorite, bedtime, buddy, never, forgets, get, charger, take, bed, book, choice, night, love, gift, child, keeps, playing, great, died, company, rocks, great, product, son, loved, died, base, seem, charge, little, dino, properly, 6, months, died, warranty, 90, days, ordering, another, one, hopes, lasts, longer, really, great, light, subsequent, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[dont, waste, money, 4, different, animals, posession, last, year, kinderglo, great, customer, service, lights, crap, one, lasted, week, another, month, third, one, lasted, day, final, one, lasted, 3, months, either, charger, stops, charging, light, light, stops, taking, charge, whatever, wasted, 70, total, included, cost, first, light, shipping, light, back, stopped, working, get, replacement, note, nobody, touched, lights, husband, charged, various, kitchen, outlets, reach, son, set, dresser, reach, bedtime, please, waste, money, like, going, ask, money, back, lets, hope, get, back, wonderful, charging, station, really, fragile, purchased, animals, trex, brontosaurus, owl, three, sons, opinion, based, three, items, merely, one, foremost, boys, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>[replaces, standard, baggies, ages, another, reviewer, said, perfect, ages, love, fact, use, snack, cup, pack, daughter, orange, color, one, vibrant, misplaced, perfect, put, cheerios, little, ones, put, snacks, bigger, cereal, frost, mini, wheats, holds, handful, overeat, feared, lid, might, hard, open, easy, open, without, much, effort, yet, holds, wonderful, seal, hand, washed, cup, like, fact, top, shelf, dishwasher, safe, bonuses, see, cup, surface, know, getting, bottom, fits, perfectly, cars, cup, holder, grab, bite, without, look, away, since, lid, opening, generous, fact, bpa, pvc, free, feel, lot, better, using, daughter, also, someone, else, stated, replaces, dreadful, baggies, anything, put, baggie, ends, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[oxo, tot, snack, cup, handy, limited, oxo, tot, flip, top, snack, cup, semi, handy, snack, container, small, children, adults, well, snack, cup, holds, small, portion, favorite, snack, takes, little, space, sized, right, fit, small, hands, two, little, girls, like, youngsters, often, need, snack, giving, large, box, favorite, chip, cracker, isn, wise, move, discovered, one, occasion, small, container, like, young, ones, carry, snack, around, serve, since, container, small, also, limits, amount, eat, adults, also, use, snack, container, many, like, compact, size, fit, purses, small, spaces, without, problem, handy, storage, small, bite, size, portions, however, small, size, also, liability, perspective, adult, amount, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>[fantastic, say, enough, good, things, toy, perfect, flashing, lights, bright, colors, catchy, music, plays, certain, actions, performed, continuously, like, many, toys, peek, blocks, awesome, rounded, corners, edges, interesting, moving, parts, inside, etc, place, blocks, top, incrediblock, lady, speaks, name, object, inside, block, cracks, daughter, every, single, time, spent, countless, hours, moving, side, side, incrediblock, investigating, fascinating, things, also, perfect, height, new, walker, stander, play, probably, coolest, part, perspective, mom, incrediblock, built, block, storage, playtime, put, blocks, away, behind, little, door, avoid, stepping, blocks, house, highly, recommend, buying, set, extra, blocks, got, alphabet, set, re, great, supplement, included, blocks, think, comes, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>[peek, blocks, work, toy, bought, toy, thought, peek, blocks, would, work, toy, thought, toy, would, say, letter, name, item, block, placed, top, 8, blocks, come, wouldn, purchased, toy, known, 8, blocks, would, really, work, alphabet, blocks, actually, say, wrong, item, rather, playing, song, confusing, buy, big, piece, plastic, junk, thought, d, get, lot, bang, buck, educational, potential, alphabet, blocks, totally, lost, toy, bad, couldn, taken, pretty, cool, technology, bit, include, alphabet, blocks]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusterID  positiveReview  \\\n",
       "0  0          True             \n",
       "1  0          False            \n",
       "2  1          True             \n",
       "3  1          False            \n",
       "4  2          True             \n",
       "5  2          False            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       tokens  \n",
       "0  [great, nightlight, replacement, nightlight, died, 4, 1, 2, years, use, terrific, design, soft, design, ease, use, make, perfect, nightlight, son, 4, 1, 2, loves, sharp, tooth, dinosaur, changing, colors, even, perfected, selecting, color, likes, night, highly, recommend, product, one, child, great, gift, sent, rex, gift, boy, mother, wrote, love, tyrannosaurus, light, anthony, favorite, bedtime, buddy, never, forgets, get, charger, take, bed, book, choice, night, love, gift, child, keeps, playing, great, died, company, rocks, great, product, son, loved, died, base, seem, charge, little, dino, properly, 6, months, died, warranty, 90, days, ordering, another, one, hopes, lasts, longer, really, great, light, subsequent, ...]                                                                                \n",
       "1  [dont, waste, money, 4, different, animals, posession, last, year, kinderglo, great, customer, service, lights, crap, one, lasted, week, another, month, third, one, lasted, day, final, one, lasted, 3, months, either, charger, stops, charging, light, light, stops, taking, charge, whatever, wasted, 70, total, included, cost, first, light, shipping, light, back, stopped, working, get, replacement, note, nobody, touched, lights, husband, charged, various, kitchen, outlets, reach, son, set, dresser, reach, bedtime, please, waste, money, like, going, ask, money, back, lets, hope, get, back, wonderful, charging, station, really, fragile, purchased, animals, trex, brontosaurus, owl, three, sons, opinion, based, three, items, merely, one, foremost, boys, ...]                                                    \n",
       "2  [replaces, standard, baggies, ages, another, reviewer, said, perfect, ages, love, fact, use, snack, cup, pack, daughter, orange, color, one, vibrant, misplaced, perfect, put, cheerios, little, ones, put, snacks, bigger, cereal, frost, mini, wheats, holds, handful, overeat, feared, lid, might, hard, open, easy, open, without, much, effort, yet, holds, wonderful, seal, hand, washed, cup, like, fact, top, shelf, dishwasher, safe, bonuses, see, cup, surface, know, getting, bottom, fits, perfectly, cars, cup, holder, grab, bite, without, look, away, since, lid, opening, generous, fact, bpa, pvc, free, feel, lot, better, using, daughter, also, someone, else, stated, replaces, dreadful, baggies, anything, put, baggie, ends, ...]                                                                                 \n",
       "3  [oxo, tot, snack, cup, handy, limited, oxo, tot, flip, top, snack, cup, semi, handy, snack, container, small, children, adults, well, snack, cup, holds, small, portion, favorite, snack, takes, little, space, sized, right, fit, small, hands, two, little, girls, like, youngsters, often, need, snack, giving, large, box, favorite, chip, cracker, isn, wise, move, discovered, one, occasion, small, container, like, young, ones, carry, snack, around, serve, since, container, small, also, limits, amount, eat, adults, also, use, snack, container, many, like, compact, size, fit, purses, small, spaces, without, problem, handy, storage, small, bite, size, portions, however, small, size, also, liability, perspective, adult, amount, ...]                                                                                \n",
       "4  [fantastic, say, enough, good, things, toy, perfect, flashing, lights, bright, colors, catchy, music, plays, certain, actions, performed, continuously, like, many, toys, peek, blocks, awesome, rounded, corners, edges, interesting, moving, parts, inside, etc, place, blocks, top, incrediblock, lady, speaks, name, object, inside, block, cracks, daughter, every, single, time, spent, countless, hours, moving, side, side, incrediblock, investigating, fascinating, things, also, perfect, height, new, walker, stander, play, probably, coolest, part, perspective, mom, incrediblock, built, block, storage, playtime, put, blocks, away, behind, little, door, avoid, stepping, blocks, house, highly, recommend, buying, set, extra, blocks, got, alphabet, set, re, great, supplement, included, blocks, think, comes, ...]  \n",
       "5  [peek, blocks, work, toy, bought, toy, thought, peek, blocks, would, work, toy, thought, toy, would, say, letter, name, item, block, placed, top, 8, blocks, come, wouldn, purchased, toy, known, 8, blocks, would, really, work, alphabet, blocks, actually, say, wrong, item, rather, playing, song, confusing, buy, big, piece, plastic, junk, thought, d, get, lot, bang, buck, educational, potential, alphabet, blocks, totally, lost, toy, bad, couldn, taken, pretty, cool, technology, bit, include, alphabet, blocks]                                                                                                                                                                                                                                                                                                             "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregatedDF = (polarizedDF\n",
    "                .groupBy('clusterID', 'positiveReview')\n",
    "                .agg(F.collect_list('reviews').alias('collectedReviews'))\n",
    "                .withColumn('tokens', flatten('collectedReviews'))\n",
    "                .drop('collectedReviews')\n",
    "                .sort('clusterID', bool_invert('positiveReview'))\n",
    "                .cache())\n",
    "displayDF(aggregatedDF, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5873"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregatedDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select top $N$ words ranked by TF-IDF for positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.ArrayType(T.StringType()))\n",
    "def bin_pos_top_words(words, positiveReview):\n",
    "    return words if positiveReview == True else None\n",
    "\n",
    "@F.udf(returnType=T.ArrayType(T.StringType()))\n",
    "def bin_neg_top_words(words, positiveReview):\n",
    "    return words if positiveReview == False else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "code_folding": [
     10,
     23
    ]
   },
   "outputs": [],
   "source": [
    "def top_N_words(DF, N=10):\n",
    "    '''\n",
    "    Obtains the top N words of positive and negative reviews respectively, ranked by tf-idf of entries in a DF.\n",
    "    Inputs:\n",
    "        DF: A Spark DataFrame containing columns 'clusterID', 'positiveReview' and 'tokens'.\n",
    "        N:  Number of top-ranking words to keep\n",
    "    Outputs:\n",
    "        A DataFrame of schema (_clusterID_, _positiveReview_, top_N_pos, top_N_neg)\n",
    "    '''\n",
    "    \n",
    "    def tf(tokens):\n",
    "        '''\n",
    "        Calculate the token frequency (TF) for each review.\n",
    "\n",
    "        Inputs:\n",
    "            tokens: A list of token strings.\n",
    "        Outputs:\n",
    "            A dictionary of (token, tf).\n",
    "        '''\n",
    "        N = len(tokens)\n",
    "\n",
    "        return {token: float(tokens.count(token)) / N for token in tokens}\n",
    "\n",
    "    def idf(corpusDF):\n",
    "        '''\n",
    "        Calculate the inverse document frequency for the corpusDF.\n",
    "\n",
    "        Inputs:\n",
    "            corpusDF: A Spark DataFrame containing columns 'tokens'.\n",
    "        Outputs:\n",
    "            A dictionary of (token, idf).\n",
    "        '''\n",
    "        # Calculate the number of reviews\n",
    "        N = corpusDF.count()\n",
    "\n",
    "        # Create an RDD with entries (uniq_tokens_in_each_review, 1)\n",
    "        checkpointRDD = (corpusDF\n",
    "                         .select('tokens')\n",
    "                         .rdd\n",
    "                         .flatMap(lambda tokens: list(set(tokens[0])))\n",
    "                         .map(lambda token: (token, 1)))\n",
    "\n",
    "        # Produce a dict containing (token, idf)\n",
    "        return (checkpointRDD\n",
    "                .reduceByKey(lambda a, b: a + b)\n",
    "                .mapValues(lambda count: float(count) / N)\n",
    "                .collectAsMap())\n",
    "    \n",
    "    # Calculate tf's as an RDD\n",
    "    tfRDD = (DF\n",
    "           .select('clusterID', 'positiveReview', 'tokens')\n",
    "           .rdd\n",
    "           .map(lambda (clusterID, positiveReview, tokens): ((clusterID, positiveReview), tf(tokens))))\n",
    "    \n",
    "    # Calculate idf's as a dict and return a broadcasted instance\n",
    "    idfs_broadcast = spark.sparkContext.broadcast(idf(DF.select('tokens')))\n",
    "    \n",
    "    # Calculate tfidf as an rdd of (clusterID, positiveReview, top_N_tokens)\n",
    "    topNwordsRDD = (tfRDD\n",
    "                    .mapValues(lambda tf_dict: [(token, float(tf_dict[token]) / idfs_broadcast.value[token]) for token in tf_dict.keys()])\n",
    "                    .sortBy(lambda ((clusterID, positiveReview), tfidfs): ((clusterID, not positiveReview, sorted(tfidfs, key=lambda (token, tfidf): -tfidf))))\n",
    "                    .mapValues(lambda tfidfs: map(lambda (token, tfidf): token, tfidfs)[:N])\n",
    "                    .map(lambda ((clusterID, positiveReview), top_N_tokens): (clusterID, positiveReview, top_N_tokens))\n",
    "                    .cache())\n",
    "    \n",
    "#     return (tfRDD, idf(DF.select('tokens')), topNwordsRDD)\n",
    "#     return topNwordsRDD\n",
    "    \n",
    "    # Transform topNwordsRDD to an RDD of form (clusterID, top_N_positive, top_N_negative)\n",
    "    temp_schema = T.StructType([\n",
    "        (T.StructField('clusterID', T.IntegerType())),\n",
    "        (T.StructField('positiveReview', T.BooleanType())),\n",
    "        (T.StructField('topWords', T.ArrayType(T.StringType())))\n",
    "    ])\n",
    "    \n",
    "    return (spark\n",
    "            .createDataFrame(topNwordsRDD, temp_schema)\n",
    "            .withColumn('posWords', bin_pos_top_words('topWords', 'positiveReview'))\n",
    "            .withColumn('negWords', bin_neg_top_words('topWords', 'positiveReview'))\n",
    "            .drop('positiveReview', 'topWords')\n",
    "            .groupBy('clusterID')\n",
    "            .agg(F.collect_list('posWords').alias('posWords'), F.collect_list('negWords').alias('negWords'))\n",
    "            .cache()\n",
    "#             .select('clusterID', F.explode('posWords').alias('posWords'), 'negWords')\n",
    "#             .select('clusterID', 'posWords', F.explode('negWords').alias('negWords')))\n",
    "#                 .groupBy('clusterID')\n",
    "#                 .agg(F.collect_list('topWords').alias('posAndNegWords'))\n",
    "#                 .rdd\n",
    "#                 .map(lambda (clusterID, words): (clusterID, words[0], words[1])))\n",
    "           )\n",
    "    \n",
    "#     return finalRDD\n",
    "    \n",
    "    # Return finalRDD as a dataframe\n",
    "    final_schema = T.StructType([\n",
    "        (T.StructField('clusterID', T.IntegerType())),\n",
    "        (T.StructField('posWords', T.ArrayType(T.StringType()))),\n",
    "        (T.StructField('negWords', T.ArrayType(T.StringType())))\n",
    "    ])\n",
    "    \n",
    "    return (spark\n",
    "            .createDataFrame(finalRDD, final_schema)\n",
    "            .sort('clusterID')\n",
    "            .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterID</th>\n",
       "      <th>posWords</th>\n",
       "      <th>negWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>[managed, lack, sleek, sleep, go, bank, compact, outgrowing, jogger, concerned]</td>\n",
       "      <td>[mini, right, thankfully, anyway, one, single, hassle, purchased, wonderful, actually]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>463</td>\n",
       "      <td>[son, summer, since, super, mom, switched, money, saver, anyway, wintee]</td>\n",
       "      <td>[refund, child, cheap, years, looks, synthetic, giant, clasps, fit, ment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471</td>\n",
       "      <td>[sage, course, colors, looks, imagined, perfect, based, patches, better, theme]</td>\n",
       "      <td>[demand, month, shortcomings, hate, causes, improperly, jogger, description, send, finally]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusterID  \\\n",
       "0  148         \n",
       "1  463         \n",
       "2  471         \n",
       "\n",
       "                                                                          posWords  \\\n",
       "0  [managed, lack, sleek, sleep, go, bank, compact, outgrowing, jogger, concerned]   \n",
       "1  [son, summer, since, super, mom, switched, money, saver, anyway, wintee]          \n",
       "2  [sage, course, colors, looks, imagined, perfect, based, patches, better, theme]   \n",
       "\n",
       "                                                                                      negWords  \n",
       "0  [mini, right, thankfully, anyway, one, single, hassle, purchased, wonderful, actually]       \n",
       "1  [refund, child, cheap, years, looks, synthetic, giant, clasps, fit, ment]                    \n",
       "2  [demand, month, shortcomings, hate, causes, improperly, jogger, description, send, finally]  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayDF(finalRDD\n",
    " .withColumn('posWords', bin_pos_top_words('topWords', 'positiveReview'))\n",
    " .withColumn('negWords', bin_neg_top_words('topWords', 'positiveReview'))\n",
    " .drop('positiveReview', 'topWords')\n",
    " .groupBy('clusterID')\n",
    " .agg(F.collect_list('posWords').alias('posWords'), F.collect_list('negWords').alias('negWords'))\n",
    " .select('clusterID', F.explode('posWords').alias('posWords'), 'negWords')\n",
    " .select('clusterID', 'posWords', F.explode('negWords').alias('negWords'))\n",
    " , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterID</th>\n",
       "      <th>posAndNegWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2366</td>\n",
       "      <td>[[individually, love, sweet, 80, find, best, even, 00, compared, girls]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2866</td>\n",
       "      <td>[[help, less, scratches, damage, nursery, advertised, go, tone, assembled, roomy]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3175</td>\n",
       "      <td>[[son, old, figure, snacks, able, wasn, idea, month, ended, good]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3749</td>\n",
       "      <td>[[hooks, move, rest, month, padded, using, years, yes, bit, make]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1483</td>\n",
       "      <td>[[even, like, sheet, fabric, would, thin, disposable, cheap, completely, hemmed]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1507</td>\n",
       "      <td>[[givers, lack, sooo, four, catch, paper, sleep, go, love, yes]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2580</td>\n",
       "      <td>[[washcloth, didn, ordered, money, results, one, newborn, baby, something, want]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3475</td>\n",
       "      <td>[[cute, stores, limited, september, money, course, colors, sleep, saving, still]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1975</td>\n",
       "      <td>[[life, size, perfect, cut, aren, stuck, 7, white, really, nice]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2443</td>\n",
       "      <td>[[full, old, ve, pointing, snacks, hands, sign, doesn, one, used]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusterID  \\\n",
       "0  2366        \n",
       "1  2866        \n",
       "2  3175        \n",
       "3  3749        \n",
       "4  1483        \n",
       "5  1507        \n",
       "6  2580        \n",
       "7  3475        \n",
       "8  1975        \n",
       "9  2443        \n",
       "\n",
       "                                                                       posAndNegWords  \n",
       "0  [[individually, love, sweet, 80, find, best, even, 00, compared, girls]]            \n",
       "1  [[help, less, scratches, damage, nursery, advertised, go, tone, assembled, roomy]]  \n",
       "2  [[son, old, figure, snacks, able, wasn, idea, month, ended, good]]                  \n",
       "3  [[hooks, move, rest, month, padded, using, years, yes, bit, make]]                  \n",
       "4  [[even, like, sheet, fabric, would, thin, disposable, cheap, completely, hemmed]]   \n",
       "5  [[givers, lack, sooo, four, catch, paper, sleep, go, love, yes]]                    \n",
       "6  [[washcloth, didn, ordered, money, results, one, newborn, baby, something, want]]   \n",
       "7  [[cute, stores, limited, september, money, course, colors, sleep, saving, still]]   \n",
       "8  [[life, size, perfect, cut, aren, stuck, 7, white, really, nice]]                   \n",
       "9  [[full, old, ve, pointing, snacks, hands, sign, doesn, one, used]]                  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def column_sort_decorator(positiveReview):\n",
    "    def \n",
    "    return F.udf()\n",
    "\n",
    "@F.udf(returnType=T.ArrayType(T.StringType()))\n",
    "def bin_top_words(words, positiveReview, binOnPositiveCol):\n",
    "    return words if positiveReview == binOnPositiveCol else None\n",
    "\n",
    "displayDF(penulRDD\n",
    " .groupBy('clusterID')\n",
    " .agg(F.collect_list('topWords').alias('posAndNegWords'))\n",
    "                  .filter(F.udf(lambda x: len(x) < 2, T.BooleanType())('posAndNegWords'))\n",
    "#  .rdd\n",
    " .map(lambda (clusterID, words): (clusterID, words[0], words[1]))\n",
    "#  .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterID</th>\n",
       "      <th>posAndNegWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>[[managed, lack, sleek, sleep, go, bank, compact, outgrowing, jogger, concerned], [mini, right, thankfully, anyway, one, single, hassle, purchased, wonderful, actually]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>463</td>\n",
       "      <td>[[son, summer, since, super, mom, switched, money, saver, anyway, wintee], [refund, child, cheap, years, looks, synthetic, giant, clasps, fit, ment]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471</td>\n",
       "      <td>[[sage, course, colors, looks, imagined, perfect, based, patches, better, theme], [demand, month, shortcomings, hate, causes, improperly, jogger, description, send, finally]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusterID  \\\n",
       "0  148         \n",
       "1  463         \n",
       "2  471         \n",
       "\n",
       "                                                                                                                                                                   posAndNegWords  \n",
       "0  [[managed, lack, sleek, sleep, go, bank, compact, outgrowing, jogger, concerned], [mini, right, thankfully, anyway, one, single, hassle, purchased, wonderful, actually]]       \n",
       "1  [[son, summer, since, super, mom, switched, money, saver, anyway, wintee], [refund, child, cheap, years, looks, synthetic, giant, clasps, fit, ment]]                           \n",
       "2  [[sage, course, colors, looks, imagined, perfect, based, patches, better, theme], [demand, month, shortcomings, hate, causes, improperly, jogger, description, send, finally]]  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayDF(penulRDD, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o2428.cache.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 409.0 failed 1 times, most recent failure: Lost task 7.0 in stage 409.0 (TID 13789, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-139-4b7f6bf48a7d>\", line 6, in <lambda>\nIndexError: list index out of range\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.next(PythonRDD.scala:156)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.next(PythonRDD.scala:152)\n\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)\n\tat org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:263)\n\tat org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:261)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:266)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$.prepareShuffleDependency(ShuffleExchange.scala:221)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.prepareShuffleDependency(ShuffleExchange.scala:87)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:124)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:115)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.doExecute(ShuffleExchange.scala:115)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:252)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:386)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n\tat org.apache.spark.sql.execution.columnar.InMemoryRelation.buildBuffers(InMemoryRelation.scala:91)\n\tat org.apache.spark.sql.execution.columnar.InMemoryRelation.<init>(InMemoryRelation.scala:86)\n\tat org.apache.spark.sql.execution.columnar.InMemoryRelation$.apply(InMemoryRelation.scala:42)\n\tat org.apache.spark.sql.execution.CacheManager$$anonfun$cacheQuery$1.apply(CacheManager.scala:100)\n\tat org.apache.spark.sql.execution.CacheManager.writeLock(CacheManager.scala:68)\n\tat org.apache.spark.sql.execution.CacheManager.cacheQuery(CacheManager.scala:92)\n\tat org.apache.spark.sql.Dataset.persist(Dataset.scala:2513)\n\tat org.apache.spark.sql.Dataset.cache(Dataset.scala:2523)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-139-4b7f6bf48a7d>\", line 6, in <lambda>\nIndexError: list index out of range\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.next(PythonRDD.scala:156)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.next(PythonRDD.scala:152)\n\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)\n\tat org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:263)\n\tat org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:261)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-a7e17bea5fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m actualFinalDF = (spark\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactualFinalRDD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clusterID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         .cache())\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \"\"\"\n\u001b[1;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/py4j/protocol.pyc\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2428.cache.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 409.0 failed 1 times, most recent failure: Lost task 7.0 in stage 409.0 (TID 13789, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-139-4b7f6bf48a7d>\", line 6, in <lambda>\nIndexError: list index out of range\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.next(PythonRDD.scala:156)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.next(PythonRDD.scala:152)\n\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)\n\tat org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:263)\n\tat org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:261)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\n\tat org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:266)\n\tat org.apache.spark.RangePartitioner.<init>(Partitioner.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$.prepareShuffleDependency(ShuffleExchange.scala:221)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.prepareShuffleDependency(ShuffleExchange.scala:87)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:124)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange$$anonfun$doExecute$1.apply(ShuffleExchange.scala:115)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchange.doExecute(ShuffleExchange.scala:115)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:252)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:386)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:117)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:138)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:135)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:116)\n\tat org.apache.spark.sql.execution.columnar.InMemoryRelation.buildBuffers(InMemoryRelation.scala:91)\n\tat org.apache.spark.sql.execution.columnar.InMemoryRelation.<init>(InMemoryRelation.scala:86)\n\tat org.apache.spark.sql.execution.columnar.InMemoryRelation$.apply(InMemoryRelation.scala:42)\n\tat org.apache.spark.sql.execution.CacheManager$$anonfun$cacheQuery$1.apply(CacheManager.scala:100)\n\tat org.apache.spark.sql.execution.CacheManager.writeLock(CacheManager.scala:68)\n\tat org.apache.spark.sql.execution.CacheManager.cacheQuery(CacheManager.scala:92)\n\tat org.apache.spark.sql.Dataset.persist(Dataset.scala:2513)\n\tat org.apache.spark.sql.Dataset.cache(Dataset.scala:2523)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-139-4b7f6bf48a7d>\", line 6, in <lambda>\nIndexError: list index out of range\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.next(PythonRDD.scala:156)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.next(PythonRDD.scala:152)\n\tat org.apache.spark.InterruptibleIterator.next(InterruptibleIterator.scala:40)\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.util.random.SamplingUtils$.reservoirSampleAndCount(SamplingUtils.scala:41)\n\tat org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:263)\n\tat org.apache.spark.RangePartitioner$$anonfun$9.apply(Partitioner.scala:261)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Return finalRDD as a dataframe\n",
    "final_schema = T.StructType([\n",
    "    (T.StructField('clusterID', T.IntegerType())),\n",
    "    (T.StructField('posWords', T.ArrayType(T.StringType()))),\n",
    "    (T.StructField('negWords', T.ArrayType(T.StringType())))\n",
    "])\n",
    "\n",
    "actualFinalDF = (spark\n",
    "        .createDataFrame(actualFinalRDD, final_schema)\n",
    "        .sort('clusterID')\n",
    "        .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "displayDF(actualFinalDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterID</th>\n",
       "      <th>posWords</th>\n",
       "      <th>negWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>[managed, lack, sleek, sleep, go, bank, compact, outgrowing, jogger, concerned]</td>\n",
       "      <td>[mini, right, thankfully, anyway, one, single, hassle, purchased, wonderful, actually]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>463</td>\n",
       "      <td>[son, summer, since, super, mom, switched, money, saver, anyway, wintee]</td>\n",
       "      <td>[refund, child, cheap, years, looks, synthetic, giant, clasps, fit, ment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471</td>\n",
       "      <td>[sage, course, colors, looks, imagined, perfect, based, patches, better, theme]</td>\n",
       "      <td>[demand, month, shortcomings, hate, causes, improperly, jogger, description, send, finally]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>[consider, chinese, month, hanging, go, row, hold, contours, worth, brown]</td>\n",
       "      <td>[chinese, money, clothdiapers, sent, cheap, month, colors, poopy, advertised, go]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1088</td>\n",
       "      <td>[cute, set, rating, colors, buy, want, shake, impossible, still, perfect]</td>\n",
       "      <td>[feed, didn, metal, half, tended, son, utensils, fine, size, even]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1238</td>\n",
       "      <td>[limited, since, reviewers, knotted, relieve, rod, results, month, ladders, known]</td>\n",
       "      <td>[concept, month, chewable, sleep, hanging, go, saved, causes, illegible, finally]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1342</td>\n",
       "      <td>[hooks, month, mp3, children, carpet, segments, young, stable, whack, putting]</td>\n",
       "      <td>[concept, overpriced, chinese, money, cheap, month, shape, mp3, interpreter, ripoff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1580</td>\n",
       "      <td>[valve, switched, personally, people, resistance, month, four, known, supplement, sleep]</td>\n",
       "      <td>[wrestle, lack, month, themes, straws, go, hate, assembled, issues, seemed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1591</td>\n",
       "      <td>[cute, infant, holds, less, reviewers, stays, displayed, damage, leads, held]</td>\n",
       "      <td>[managed, gp, beware, dollar, scuffed, four, go, children, compact, overpricd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1645</td>\n",
       "      <td>[scratch, beware, scratches, month, cheerful, mild, softer, go, saved, carpet]</td>\n",
       "      <td>[saying, dyes, consider, contacted, scrubbing, move, ewonderworld, results, month, discovered]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusterID  \\\n",
       "0  148         \n",
       "1  463         \n",
       "2  471         \n",
       "3  496         \n",
       "4  1088        \n",
       "5  1238        \n",
       "6  1342        \n",
       "7  1580        \n",
       "8  1591        \n",
       "9  1645        \n",
       "\n",
       "                                                                                   posWords  \\\n",
       "0  [managed, lack, sleek, sleep, go, bank, compact, outgrowing, jogger, concerned]            \n",
       "1  [son, summer, since, super, mom, switched, money, saver, anyway, wintee]                   \n",
       "2  [sage, course, colors, looks, imagined, perfect, based, patches, better, theme]            \n",
       "3  [consider, chinese, month, hanging, go, row, hold, contours, worth, brown]                 \n",
       "4  [cute, set, rating, colors, buy, want, shake, impossible, still, perfect]                  \n",
       "5  [limited, since, reviewers, knotted, relieve, rod, results, month, ladders, known]         \n",
       "6  [hooks, month, mp3, children, carpet, segments, young, stable, whack, putting]             \n",
       "7  [valve, switched, personally, people, resistance, month, four, known, supplement, sleep]   \n",
       "8  [cute, infant, holds, less, reviewers, stays, displayed, damage, leads, held]              \n",
       "9  [scratch, beware, scratches, month, cheerful, mild, softer, go, saved, carpet]             \n",
       "\n",
       "                                                                                         negWords  \n",
       "0  [mini, right, thankfully, anyway, one, single, hassle, purchased, wonderful, actually]          \n",
       "1  [refund, child, cheap, years, looks, synthetic, giant, clasps, fit, ment]                       \n",
       "2  [demand, month, shortcomings, hate, causes, improperly, jogger, description, send, finally]     \n",
       "3  [chinese, money, clothdiapers, sent, cheap, month, colors, poopy, advertised, go]               \n",
       "4  [feed, didn, metal, half, tended, son, utensils, fine, size, even]                              \n",
       "5  [concept, month, chewable, sleep, hanging, go, saved, causes, illegible, finally]               \n",
       "6  [concept, overpriced, chinese, money, cheap, month, shape, mp3, interpreter, ripoff]            \n",
       "7  [wrestle, lack, month, themes, straws, go, hate, assembled, issues, seemed]                     \n",
       "8  [managed, gp, beware, dollar, scuffed, four, go, children, compact, overpricd]                  \n",
       "9  [saying, dyes, consider, contacted, scrubbing, move, ewonderworld, results, month, discovered]  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDF = top_N_words(aggregatedDF)\n",
    "displayDF(finalDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2626"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterID</th>\n",
       "      <th>posWords</th>\n",
       "      <th>negWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317</td>\n",
       "      <td>[cute, salon, show, cheap, soon, decals, looks, go, glue, perfect]</td>\n",
       "      <td>[since, less, money, move, soon, decals, lovebirds, looks, bedroom, still]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusterID  \\\n",
       "0  317         \n",
       "\n",
       "                                                             posWords  \\\n",
       "0  [cute, salon, show, cheap, soon, decals, looks, go, glue, perfect]   \n",
       "\n",
       "                                                                     negWords  \n",
       "0  [since, less, money, move, soon, decals, lovebirds, looks, bedroom, still]  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayDF(finalDF.filter(F.col('clusterID') == 317))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Remove digits (maybe except years)\n",
    "- Filter out common top words that appear in both posWords and negWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analyzer Script\n",
    "The following code analyzes how frequent words appear in product titles of a given cluster. This is used as a tentative proxy for clustering effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "code_folding": [
     14,
     28,
     36
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load stopwords into list\n",
    "with open('stopwords.csv', 'r') as csvFile:\n",
    "    fileReader = csv.reader(csvFile)\n",
    "    stopwords = []\n",
    "    for word in fileReader:\n",
    "        stopwords.extend(word)\n",
    "        \n",
    "# Add '' to stopwords\n",
    "stopwords.append('')\n",
    "\n",
    "# Broadcast stopwords\n",
    "stopwords_broadcast = spark.sparkContext.broadcast(stopwords)\n",
    "\n",
    "@F.udf(returnType=T.ArrayType(T.StringType()))\n",
    "def tokenize_set_and_filter_stopwords(text):\n",
    "    '''\n",
    "    Tokenizes a list of words, before filtering for stopwords. Return a setted list of words.\n",
    "    \n",
    "    Input:\n",
    "        text: A string.\n",
    "    Returns:\n",
    "        A list of setted words with stopwords removed.\n",
    "    '''\n",
    "    string_set = set(re.split(r'\\W+', text.lower()))\n",
    "\n",
    "    return [word for word in string_set if word not in stopwords_broadcast.value]\n",
    "\n",
    "@F.udf(returnType=T.IntegerType())\n",
    "def assign_clusterID():\n",
    "    return random.randint(0, 10)\n",
    "\n",
    "@F.udf(returnType=T.ArrayType(T.StructType([\n",
    "    T.StructField('token', T.StringType()),\n",
    "    T.StructField('frequency', T.FloatType())\n",
    "])))\n",
    "# @F.udf\n",
    "def analyze_word_frequency(tokens, N=10):\n",
    "    '''\n",
    "    Calculate the frequency of words appearing in titles of a given cluster.\n",
    "    \n",
    "    Inputs:\n",
    "        tokens: A list of list of words.\n",
    "    Returns:\n",
    "        A list of tuple (token, frequency) of the top N words, sorted in decreasing frequency.\n",
    "    '''\n",
    "    counter = Counter(word for words in tokens for word in words)\n",
    "    L = sum(counter.values())\n",
    "    return map(lambda (k, v): (k, float(v) / L), \n",
    "               counter.most_common()[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>clusterId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188399313</td>\n",
       "      <td>Lifefactory 4oz BPA Free Glass Baby Bottles - 4-pack-raspberry and Lilac</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188399518</td>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188399399</td>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316967297</td>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>615447279</td>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>670062049</td>\n",
       "      <td>5 Pink Gumdrops + One Pacifier Clip</td>\n",
       "      <td>2372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>705391752</td>\n",
       "      <td>A Tale of Baby's Days with Peter Rabbit</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>097293751X</td>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, Schedule Log</td>\n",
       "      <td>3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>974671517</td>\n",
       "      <td>Wee Gallery Twins Board Book</td>\n",
       "      <td>2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>980027519</td>\n",
       "      <td>Nature's Lullabies First and Second Year Calendars</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  \\\n",
       "0  188399313    \n",
       "1  188399518    \n",
       "2  188399399    \n",
       "3  316967297    \n",
       "4  615447279    \n",
       "5  670062049    \n",
       "6  705391752    \n",
       "7  097293751X   \n",
       "8  974671517    \n",
       "9  980027519    \n",
       "\n",
       "                                                                                               title  \\\n",
       "0  Lifefactory 4oz BPA Free Glass Baby Bottles - 4-pack-raspberry and Lilac                            \n",
       "1  Planetwise Flannel Wipes                                                                            \n",
       "2  Planetwise Wipe Pouch                                                                               \n",
       "3  Annas Dream Full Quilt with 2 Shams                                                                 \n",
       "4  Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book   \n",
       "5  5 Pink Gumdrops + One Pacifier Clip                                                                 \n",
       "6  A Tale of Baby's Days with Peter Rabbit                                                             \n",
       "7  Baby Tracker&reg; - Daily Childcare Journal, Schedule Log                                           \n",
       "8  Wee Gallery Twins Board Book                                                                        \n",
       "9  Nature's Lullabies First and Second Year Calendars                                                  \n",
       "\n",
       "   clusterId  \n",
       "0  523        \n",
       "1  975        \n",
       "2  802        \n",
       "3  281        \n",
       "4  1130       \n",
       "5  2372       \n",
       "6  1014       \n",
       "7  3044       \n",
       "8  2231       \n",
       "9  11         "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babyMetaDF = raw1DF\n",
    "displayDF(babyMetaDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterID</th>\n",
       "      <th>analyze_word_frequency(tokens)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>[(baby, 0.0666666701436), (mini, 0.0555555559695), (jogger, 0.0555555559695), (city, 0.0444444455206), (stroller, 0.0444444455206), (bassinet, 0.0222222227603), (co, 0.0222222227603), (arc, 0.0222222227603), (arm, 0.0222222227603), (reach, 0.0222222227603)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>463</td>\n",
       "      <td>[(cover, 0.136363640428), (strap, 0.0757575780153), (little, 0.0757575780153), (carr, 0.0757575780153), (pink, 0.0454545468092), (blue, 0.0454545468092), (classic, 0.0303030312061), (eddie, 0.0303030312061), (cozy, 0.0303030312061), (reversible, 0.0303030312061)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471</td>\n",
       "      <td>[(tote, 0.0759493634105), (diaper, 0.0632911399007), (bag, 0.0632911399007), (trend, 0.0506329126656), (pink, 0.0506329126656), (jogger, 0.0506329126656), (banana, 0.0506329126656), (baby, 0.0506329126656), (charlie, 0.0506329126656), (black, 0.0379746817052)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1088</td>\n",
       "      <td>[(munchkin, 0.0549450553954), (spoon, 0.0549450553954), (set, 0.0329670347273), (6, 0.0329670347273), (fork, 0.0329670347273), (green, 0.0329670347273), (piece, 0.0329670347273), (pack, 0.0329670347273), (trainer, 0.0219780225307), (toddler, 0.0219780225307)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1238</td>\n",
       "      <td>[(chewbeads, 0.0523415990174), (bag, 0.0330578498542), (baby, 0.0330578498542), (lassig, 0.0303030312061), (wrap, 0.0192837473005), (charles, 0.0165289249271), (bracelet, 0.0165289249271), (cornelia, 0.0165289249271), (bangle, 0.0165289249271), (diaper, 0.0165289249271)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1342</td>\n",
       "      <td>[(toys, 0.0294117648154), (baby, 0.0294117648154), (8gb, 0.0147058824077), (mini, 0.0147058824077), (infant, 0.0147058824077), (hhz102, 0.0147058824077), (todays, 0.0147058824077), (apple, 0.0147058824077), (clip, 0.0147058824077), (cute, 0.0147058824077)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1580</td>\n",
       "      <td>[(mam, 0.0954356864095), (bottle, 0.0954356864095), (ounce, 0.0705394223332), (pack, 0.0580912865698), (anti, 0.0456431545317), (colic, 0.0456431545317), (5, 0.0414937771857), (3, 0.0373443998396), (baby, 0.0373443998396), (2, 0.0331950224936)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1591</td>\n",
       "      <td>[(baby, 0.0568181835115), (jogger, 0.0568181835115), (carry, 0.0454545468092), (bag, 0.0454545468092), (stroller, 0.0454545468092), (city, 0.0340909101069), (mini, 0.0227272734046), (rain, 0.0227272734046), (micro, 0.0227272734046), (cover, 0.0227272734046)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1645</td>\n",
       "      <td>[(quot, 0.0725806429982), (thick, 0.0645161271095), (24, 0.0645161271095), (x, 0.0645161271095), (mats, 0.0564516112208), (9, 0.0564516112208), (16, 0.0564516112208), (set, 0.0483870953321), (48, 0.0403225794435), (square, 0.0322580635548)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1829</td>\n",
       "      <td>[(light, 0.12195122242), (night, 0.12195122242), (crystal, 0.113821141422), (swarovski, 0.113821141422), (gold, 0.0894308909774), (24k, 0.0894308909774), (clear, 0.0650406479836), (heart, 0.0243902429938), (chrome, 0.0243902429938), (fairy, 0.0243902429938)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusterID  \\\n",
       "0  148         \n",
       "1  463         \n",
       "2  471         \n",
       "3  1088        \n",
       "4  1238        \n",
       "5  1342        \n",
       "6  1580        \n",
       "7  1591        \n",
       "8  1645        \n",
       "9  1829        \n",
       "\n",
       "                                                                                                                                                                                                                                                    analyze_word_frequency(tokens)  \n",
       "0  [(baby, 0.0666666701436), (mini, 0.0555555559695), (jogger, 0.0555555559695), (city, 0.0444444455206), (stroller, 0.0444444455206), (bassinet, 0.0222222227603), (co, 0.0222222227603), (arc, 0.0222222227603), (arm, 0.0222222227603), (reach, 0.0222222227603)]                \n",
       "1  [(cover, 0.136363640428), (strap, 0.0757575780153), (little, 0.0757575780153), (carr, 0.0757575780153), (pink, 0.0454545468092), (blue, 0.0454545468092), (classic, 0.0303030312061), (eddie, 0.0303030312061), (cozy, 0.0303030312061), (reversible, 0.0303030312061)]          \n",
       "2  [(tote, 0.0759493634105), (diaper, 0.0632911399007), (bag, 0.0632911399007), (trend, 0.0506329126656), (pink, 0.0506329126656), (jogger, 0.0506329126656), (banana, 0.0506329126656), (baby, 0.0506329126656), (charlie, 0.0506329126656), (black, 0.0379746817052)]             \n",
       "3  [(munchkin, 0.0549450553954), (spoon, 0.0549450553954), (set, 0.0329670347273), (6, 0.0329670347273), (fork, 0.0329670347273), (green, 0.0329670347273), (piece, 0.0329670347273), (pack, 0.0329670347273), (trainer, 0.0219780225307), (toddler, 0.0219780225307)]              \n",
       "4  [(chewbeads, 0.0523415990174), (bag, 0.0330578498542), (baby, 0.0330578498542), (lassig, 0.0303030312061), (wrap, 0.0192837473005), (charles, 0.0165289249271), (bracelet, 0.0165289249271), (cornelia, 0.0165289249271), (bangle, 0.0165289249271), (diaper, 0.0165289249271)]  \n",
       "5  [(toys, 0.0294117648154), (baby, 0.0294117648154), (8gb, 0.0147058824077), (mini, 0.0147058824077), (infant, 0.0147058824077), (hhz102, 0.0147058824077), (todays, 0.0147058824077), (apple, 0.0147058824077), (clip, 0.0147058824077), (cute, 0.0147058824077)]                 \n",
       "6  [(mam, 0.0954356864095), (bottle, 0.0954356864095), (ounce, 0.0705394223332), (pack, 0.0580912865698), (anti, 0.0456431545317), (colic, 0.0456431545317), (5, 0.0414937771857), (3, 0.0373443998396), (baby, 0.0373443998396), (2, 0.0331950224936)]                             \n",
       "7  [(baby, 0.0568181835115), (jogger, 0.0568181835115), (carry, 0.0454545468092), (bag, 0.0454545468092), (stroller, 0.0454545468092), (city, 0.0340909101069), (mini, 0.0227272734046), (rain, 0.0227272734046), (micro, 0.0227272734046), (cover, 0.0227272734046)]               \n",
       "8  [(quot, 0.0725806429982), (thick, 0.0645161271095), (24, 0.0645161271095), (x, 0.0645161271095), (mats, 0.0564516112208), (9, 0.0564516112208), (16, 0.0564516112208), (set, 0.0483870953321), (48, 0.0403225794435), (square, 0.0322580635548)]                                 \n",
       "9  [(light, 0.12195122242), (night, 0.12195122242), (crystal, 0.113821141422), (swarovski, 0.113821141422), (gold, 0.0894308909774), (24k, 0.0894308909774), (clear, 0.0650406479836), (heart, 0.0243902429938), (chrome, 0.0243902429938), (fairy, 0.0243902429938)]               "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF = (babyMetaDF\n",
    "          .select('clusterID', tokenize_set_and_filter_stopwords('title').alias('tokens'))\n",
    "          .groupBy('clusterID')\n",
    "          .agg(F.collect_list('tokens').alias('tokens'))\n",
    "          .select('clusterID', analyze_word_frequency('tokens')).alias('tokenFrequency').alias('mostCommonWords')\n",
    "         )\n",
    "displayDF(testDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
